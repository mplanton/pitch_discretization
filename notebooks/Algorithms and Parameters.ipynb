{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms and Parameters\n",
    "\n",
    "A notebook for testing and finding the right algorithms and parameters for the _Reshift_ frequency discretization effect.\n",
    "A frequency discretization effect like _Autotune_ consists of\n",
    "\n",
    "* a pitch tracking algorithm\n",
    "\n",
    "* a nonlinear frequency scale for the target pitch\n",
    "\n",
    "* and of a pitch-shifting algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define default samplerate of 44100Hz and not 22050Hz for librosa\n",
    "# and fft length and hop size\n",
    "from presets import Preset\n",
    "import librosa as _librosa\n",
    "import librosa.display as _display\n",
    "_librosa.display = _display\n",
    "librosa = Preset(_librosa)\n",
    "\n",
    "librosa['sr'] = 44100\n",
    "librosa['n_fft'] = 4096\n",
    "librosa_hop_len = 2048\n",
    "librosa['hop_length'] = librosa_hop_len\n",
    "\n",
    "# other needed modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import the reshift algorithms\n",
    "import sys\n",
    "sys.path.insert(1, '../py') # insert at 1, 0 is the script path (or '' in REPL)\n",
    "import reshift\n",
    "\n",
    "import IPython # for IPython.display.Audio(x, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitch Tracking\n",
    "\n",
    "We use the _pYIN_ algorithm implemented by librosa for pitch tracking.\n",
    "Its [parameters](https://librosa.org/doc/latest/generated/librosa.pyin.html) are:\n",
    "\n",
    "* fmin: minimum frequency to look for\n",
    "\n",
    "* fmax: maximum frequency to look for\n",
    "\n",
    "* sr: samplingrate of input signal\n",
    "\n",
    "* frame_length: length of the frames in samples. By default, frame_length=2048\n",
    "\n",
    "* win_length: length of the window for calculating autocorrelation in samples. If None, defaults to frame_length // 2\n",
    "\n",
    "* hop_length: number of audio samples between adjacent pYIN predictions. If None, defaults to frame_length // 4\n",
    "\n",
    "* n_thresholds: number of thresholds for peak estimation.\n",
    "\n",
    "* beta_parameters: shape parameters for the beta distribution prior over thresholds.\n",
    "\n",
    "* boltzmann_parameter: shape parameter for the Boltzmann distribution prior over troughs. Larger values will assign more mass to smaller periods.\n",
    "\n",
    "* resolution: Resolution of the pitch bins. 0.01 corresponds to cents.\n",
    "\n",
    "* max_transition_rate: maximum pitch transition rate in octaves per second.\n",
    "\n",
    "* switch_prob: probability of switching from voiced to unvoiced or vice versa.\n",
    "\n",
    "* no_trough_prob: maximum probability to add to global minimum if no trough is below threshold.\n",
    "\n",
    "* fill_na: (None, float, or np.nan) default value for unvoiced frames of f0. If None, the unvoiced frames will contain a best guess value.\n",
    "\n",
    "* centerboolean: If True, the signal y is padded so that frame `D[:, t]` is centered at `y[t * hop_length]`. If False, then `D[:, t]` begins at `y[t * hop_length]`. Defaults to True, which simplifies the alignment of D onto a time grid by means of librosa.core.frames_to_samples.\n",
    "\n",
    "* pad_mode: (string or function) If center=True, this argument is passed to np.pad for padding the edges of the signal y. By default (pad_mode=\"reflect\"), y is padded on both sides with its own reflection, mirrored around its first and last sample respectively. If center=False, this argument is ignored. .. see also:: np.pad\n",
    "\n",
    "\n",
    "pYIN returns:\n",
    "\n",
    "* f0: time series of fundamental frequencies in Hertz.\n",
    "\n",
    "* voiced_flag: time series containing boolean flags indicating whether a frame is voiced or not.\n",
    "\n",
    "* voiced_prob: time series containing the probability that a frame is voiced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pYIN\n",
    "\n",
    "Let's start by anayzing the pitch of a sweep with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sine sweep\n",
    "dur = 10\n",
    "fmin = 500\n",
    "fmax = 4*500\n",
    "print(\"Sweep goes from\", fmin, \"to\", fmax, \"Hz.\")\n",
    "sr = 44100\n",
    "x_sw = librosa.chirp(fmin, fmax, sr=sr, duration=dur)\n",
    "\n",
    "# plot and play\n",
    "plt.rcParams['figure.figsize'] = [15, 5]\n",
    "reshift._my_plot(x_sw, sr, \"sine sweep\")\n",
    "IPython.display.Audio(x_sw, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pYIN analysis\n",
    "fmin = 60\n",
    "fmax = 2000\n",
    "f_0_sw, voiced_flag, voiced_probs = librosa.pyin(x_sw, fmin=fmin, fmax=fmax, sr=sr)\n",
    "\n",
    "fig, ax = plt.subplots(3)\n",
    "ax[0].plot(f_0_sw)\n",
    "ax[0].set_ylabel(\"f_0\")\n",
    "ax[1].plot(voiced_flag)\n",
    "ax[1].set_ylabel(\"voiced flag\")\n",
    "ax[2].plot(voiced_probs)\n",
    "ax[2].set_ylabel(\"voiced prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works, so now analyze a singing voice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 5\n",
    "dur = 10\n",
    "x_sing, sr = librosa.load(\"../../samples/ave-maria.wav\", offset=pos, duration=dur)\n",
    "\n",
    "# plot and play\n",
    "plt.rcParams['figure.figsize'] = [15, 5]\n",
    "reshift._my_plot(x_sing, sr, \"original signal\")\n",
    "IPython.display.Audio(x_sing, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pYIN analysis\n",
    "fmin = 60\n",
    "fmax = 2000\n",
    "pyin_frame_length = 2048\n",
    "pyin_hop_length = pyin_frame_length // 4\n",
    "f_0_sing, voiced_flag, voiced_probs = librosa.pyin(x_sing, fmin=fmin, fmax=fmax, sr=sr,\n",
    "                                                   frame_length=pyin_frame_length, hop_length=pyin_hop_length)\n",
    "\n",
    "fig, ax = plt.subplots(3)\n",
    "ax[0].plot(f_0_sing)\n",
    "ax[0].set_ylabel(\"f_0\")\n",
    "ax[1].plot(voiced_flag)\n",
    "ax[1].set_ylabel(\"voiced flag\")\n",
    "ax[2].plot(voiced_probs)\n",
    "ax[2].set_ylabel(\"voiced prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work alright too, so lets stick to the default parameters by now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nonlinear frequency scales\n",
    "\n",
    "For mapping the analyzed frequency to a target frequency, we need a scale to get the needed pitch shifting ratio.\n",
    "By now, we have a chromatic and a wholetone scale, which should be sufficient for checking parameters and algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in = np.linspace(500, 2000, 500)\n",
    "plt.plot(f_in)\n",
    "\n",
    "f_out = reshift.freq_scale(f_in, scale='chromatic', tune=440)\n",
    "plt.plot(f_out)\n",
    "\n",
    "f_out = reshift.freq_scale(f_in, scale='wholetone', tune=440)\n",
    "plt.plot(f_out, '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discretized frequency of the analyzed signals are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "\n",
    "f_0_disc_sw = reshift.freq_scale(f_0_sw, scale='chrom') # default tuning is 440Hz\n",
    "axs[0].plot(f_0_disc_sw)\n",
    "\n",
    "f_0_disc_sing = reshift.freq_scale(f_0_sing, scale='chrom')\n",
    "axs[1].plot(f_0_disc_sing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pitches are discretized to semitones.\n",
    "Since the tremolo of the singer goes over a semitone, the target frequency is still jumping between different frequencies.\n",
    "So let's try to get a flat target frequency at parts with tremolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_0_disc_sing = reshift.freq_scale(f_0_sing, scale='whole')\n",
    "plt.plot(f_0_disc_sing)\n",
    "plt.plot(f_0_sing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still jumping, so use a scale out of thirds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_0_disc_sing = reshift.freq_scale(f_0_sing, scale='thirds')\n",
    "plt.plot(f_0_disc_sing)\n",
    "plt.plot(f_0_sing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this frequency mapping looks pretty flat.\n",
    "The next step in the frequency discretization algorithm is to calculate the pitch-shifting factor $\\rho[n]$ from the analyzed pitch $f_0[n]$ and the target pitch $f_{out}[n]$\n",
    "\n",
    "$$\\rho[n] = \\frac{f_{out}[n]}{f_0[n]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rho(f_0, f_out):\n",
    "    rho = f_out / f_0\n",
    "    return rho\n",
    "\n",
    "rho_sing = get_rho(f_0_sing, f_0_disc_sing)\n",
    "plt.plot(rho_sing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the pitch-shifting factor which is needed to cancel out the deviation of the input signal from the target pitch.\n",
    "A $\\rho$ of less than one shifts down and a $\\rho$ bigger than one shifts up and one is the original pitch.\n",
    "It can be interpreted as the error signal to the target pitch.\n",
    "\n",
    "The next figure shows how the pitch is compensated to stay at discrete pitches according to the used scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original, = plt.plot(f_0_sing, label=\"original\")\n",
    "shift, = plt.plot(f_0_disc_sing * rho_sing, label=\"shift\")\n",
    "target, = plt.plot(f_0_disc_sing, label=\"target\")\n",
    "plt.legend(handles=[original, shift, target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitch-Shifting\n",
    "\n",
    "Now we need a time variable pitch-shifting algorithm in terms of the pitch-shifting factor $\\rho$.\n",
    "One of the fastest and most simple pitch-shifting algorithms is based on __Time Scale Modification (TSM) by Overlap and Add (OLA)__.\n",
    "\n",
    "Additionaly we need a strategy to handle unpitched parts of the signal.\n",
    "Let's just keep the original signal at unpitched parts for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(reshift.pitch_shift_ola)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default pYIN _frame length_ is 2048, which is the window size for calculating one pitch value.\n",
    "The default pYIN _hop size_ is `frame_length // 4`.\n",
    "The pYIN _hop size_ is the validity of the pitch-shifting factor $\\rho[n]$ at the current analyzed frequency.\n",
    "In general, there should be less frequency estimates than audio frames for pitch shifting.\n",
    "\n",
    "The _analysis window size_ $N$ and the _overlap factor_ of the OLA pitch-shifting algorithm determine the sound quality of the pitch-shifted signal and the produced artifacts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronization\n",
    "\n",
    "The output pYIN frequency estimations have to be synchronized to the pitch-shifting algorithm.\n",
    "Next we analyze the output data of librosa's pYIN implementation for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the output data sizes of pyin\n",
    "rho_N = pyin_hop_length\n",
    "actual_pyin_hop_size = (x_sing.size - pyin_frame_length) / rho_sing.size\n",
    "\n",
    "print(\"pYIN given frame length:\", pyin_frame_length, \"given rho_N = pYIN_hop_length:\", rho_N)\n",
    "print(\"actual average pYIN hop size:\", actual_pyin_hop_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x[n]; n = 0, ..., N$\n",
    "\n",
    "$N$...length of input signal\n",
    "\n",
    "$f_0[m]; m = 0, ..., M$\n",
    "\n",
    "$M$...length of frequency estimations as output from pYIN\n",
    "\n",
    "$M_z$...length of $f_0$ with zero padding\n",
    "\n",
    "$hop$...hop size of pYIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_len = 1024*8\n",
    "x_test = x_sing[:x_len]\n",
    "f0_test, flag, probs = librosa.pyin(x_test, sr=sr, frame_length=pyin_frame_length, hop_length=pyin_hop_length,\n",
    "                       fmin=200, fmax=1000)\n",
    "print(\"N:\", x_test.size, \"length of x[n] as sample rate\", sr)\n",
    "print(\"pYIN frame length:\", pyin_frame_length, \" and pYIN hop size:\", pyin_hop_length)\n",
    "print( \"M:\", f0_test.size, \"number of f0 estimations\")\n",
    "\n",
    "expected_Mz = x_test.size / pyin_hop_length\n",
    "print(\"Expected Mz:\", expected_Mz, \"calculated number of f0 estimations with zero padding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__So the number of frequency estimations of the librosa pYIN implementation is__\n",
    "\n",
    "$$M = floor(\\frac{N}{hop}) + 1$$\n",
    "\n",
    "for signals of arbitrary length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_len = 1234567\n",
    "x_test = x_sing[:x_len]\n",
    "f0_test, flag, probs = librosa.pyin(x_test, sr=sr, frame_length=pyin_frame_length, hop_length=pyin_hop_length,\n",
    "                       fmin=200, fmax=1000)\n",
    "print(\"N:\", x_test.size, \"length of x[n] as sample rate\", sr)\n",
    "print(\"pyin frame length:\", pyin_frame_length, \" and pyin hop size:\", pyin_hop_length)\n",
    "print( \"M:\", f0_test.size, \"number of f0 estimations\")\n",
    "\n",
    "expected_M = x_test.size // pyin_hop_length + 1\n",
    "print(\"Expected M:\", expected_M, \"calculated number of f0 estimations with zero padding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution:__\n",
    "Let's do zero padding of the input signal $x[n]$ to prevent problems later on.\n",
    "This is simple and it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_sing = np.concatenate((x_sing, np.zeros(x_sing.size % pyin_frame_length)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pitch-shifting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 512\n",
    "overlap_factor = 2\n",
    "y_sing = reshift.pitch_shift_ola(x_sing, sr, rho_sing, rho_N, N, overlap_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and play\n",
    "plt.rcParams['figure.figsize'] = [15, 5]\n",
    "reshift._my_plot(y_sing, sr, \"processed signal\")\n",
    "IPython.display.Audio(y_sing, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, this works, but there are a lot of artifacts and the pitch is not exactly perceived as discrete.\n",
    "We can still hear the tremolo and we can see it in the spectrogram.\n",
    "So analyze the pitch-discretized signal and ajust the algorithms parameters for a better result.\n",
    "\n",
    "\n",
    "## Analysis and Parameters\n",
    "\n",
    "First let's analyze the pitch of the pitch-discretized signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_0_y_sing, voiced_flag, voiced_probs = librosa.pyin(y_sing, fmin=fmin, fmax=fmax, sr=sr,\n",
    "                                                     frame_length=pyin_frame_length, hop_length=pyin_hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "original, = plt.plot(f_0_sing, label=\"original\")\n",
    "target, = plt.plot(f_0_disc_sing, label=\"target\")\n",
    "processed, = plt.plot(f_0_y_sing, label=\"processed\")\n",
    "plt.legend(handles=[original, target, processed])\n",
    "IPython.display.Audio(y_sing, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure reflects, what we can hear.\n",
    "As a first goal, we can focus at the part at the beginning, where the pitch is flat.\n",
    "How can we flatten the pitch?\n",
    "Which parameters can we adjust?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(reshift.pitch_shift_ola)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OLA pitch-shifting parameter improvement:__\n",
    "\n",
    "- bigger overlap factor\n",
    "\n",
    "- smaller block size N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(librosa.pyin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__pYIN pitch-tracking parameter improvement:__\n",
    "\n",
    "- use a signal with less reverb\n",
    "\n",
    "- smaller hop_length\n",
    "\n",
    "- adjust the frame_length around 2048\n",
    "\n",
    "- adjust maximum transition rate if tracking at fast pitch changes does not catch up.\n",
    "\n",
    "- adjust the pitch resolution around 0.01cents?\n",
    "\n",
    "- What does the window_length for calculating the autocorrelation exactly do?\n",
    "\n",
    "- What is n_thresholds exactly for (peak estimation)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Adjustment of OLA Pitch-Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "N = 256\n",
    "overlap_factor = 2\n",
    "\n",
    "y_sing = reshift.pitch_shift_ola(x_sing, sr, rho_sing, rho_N, N, overlap_factor)\n",
    "\n",
    "# analysis\n",
    "f_0_y_sing, voiced_flag, voiced_probs = librosa.pyin(y_sing, fmin=fmin, fmax=fmax, sr=sr,\n",
    "                                                     frame_length=pyin_frame_length, hop_length=pyin_hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot and play\n",
    "original, = plt.plot(f_0_sing, label=\"original\")\n",
    "target, = plt.plot(f_0_disc_sing, label=\"target\")\n",
    "processed, = plt.plot(f_0_y_sing, label=\"processed\")\n",
    "plt.legend(handles=[original, target, processed])\n",
    "IPython.display.Audio(y_sing, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEBUGGING:\n",
    "\n",
    "There is something wrong with the OLA-picth shifting algorithm.\n",
    "Lets do a comparison with librosa's algorithm and correct the OLA algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 512\n",
    "overlap_factor = 2\n",
    "y_dbg_rosa = reshift.pitch_shift_rosa(x_sing, rho_sing, rho_N)\n",
    "y_dbg_ola = reshift.pitch_shift_ola(x_sing, sr, rho_sing, rho_N, N, overlap_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(y_dbg_rosa, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(y_dbg_ola, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librosa's algorithm does the expected target pitch shift, but the OLA algorithm does just not work...\n",
    "\n",
    "Let's leave it like that for now and try the Rollers algorithm, which might be impemented in a non blocking manner."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
