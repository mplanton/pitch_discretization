{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms and Parameters\n",
    "\n",
    "A notebook for testing and finding the right algorithms and parameters for the _Reshift_ frequency discretization effect.\n",
    "A frequency discretization effect like _Autotune_ consists of\n",
    "\n",
    "* a pitch tracking algorithm\n",
    "\n",
    "* a nonlinear frequency scale for the target pitch\n",
    "\n",
    "* and of a pitch-shifting algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define default samplerate of 44100Hz and not 22050Hz for librosa\n",
    "# and fft length and hop size\n",
    "from presets import Preset\n",
    "import librosa as _librosa\n",
    "import librosa.display as _display\n",
    "_librosa.display = _display\n",
    "librosa = Preset(_librosa)\n",
    "\n",
    "librosa['sr'] = 44100\n",
    "librosa['n_fft'] = 4096\n",
    "librosa_hop_len = 2048\n",
    "librosa['hop_length'] = librosa_hop_len\n",
    "\n",
    "# other needed modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import the reshift algorithms\n",
    "import sys\n",
    "sys.path.insert(1, '../py') # insert at 1, 0 is the script path (or '' in REPL)\n",
    "import reshift\n",
    "\n",
    "import IPython # for IPython.display.Audio(x, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitch Tracking\n",
    "\n",
    "We use the _pYIN_ algorithm implemented by librosa for pitch tracking.\n",
    "Its [parameters](https://librosa.org/doc/latest/generated/librosa.pyin.html) are:\n",
    "\n",
    "* fmin: minimum frequency to look for\n",
    "\n",
    "* fmax: maximum frequency to look for\n",
    "\n",
    "* sr: samplingrate of input signal\n",
    "\n",
    "* frame_length: length of the frames in samples. By default, frame_length=2048\n",
    "\n",
    "* win_length: length of the window for calculating autocorrelation in samples. If None, defaults to frame_length // 2\n",
    "\n",
    "* hop_length: number of audio samples between adjacent pYIN predictions. If None, defaults to frame_length // 4\n",
    "\n",
    "* n_thresholds: number of thresholds for peak estimation.\n",
    "\n",
    "* beta_parameters: shape parameters for the beta distribution prior over thresholds.\n",
    "\n",
    "* boltzmann_parameter: shape parameter for the Boltzmann distribution prior over troughs. Larger values will assign more mass to smaller periods.\n",
    "\n",
    "* resolution: Resolution of the pitch bins. 0.01 corresponds to cents.\n",
    "\n",
    "* max_transition_rate: maximum pitch transition rate in octaves per second.\n",
    "\n",
    "* switch_prob: probability of switching from voiced to unvoiced or vice versa.\n",
    "\n",
    "* no_trough_prob: maximum probability to add to global minimum if no trough is below threshold.\n",
    "\n",
    "* fill_na: (None, float, or np.nan) default value for unvoiced frames of f0. If None, the unvoiced frames will contain a best guess value.\n",
    "\n",
    "* centerboolean: If True, the signal y is padded so that frame `D[:, t]` is centered at `y[t * hop_length]`. If False, then `D[:, t]` begins at `y[t * hop_length]`. Defaults to True, which simplifies the alignment of D onto a time grid by means of librosa.core.frames_to_samples.\n",
    "\n",
    "* pad_mode: (string or function) If center=True, this argument is passed to np.pad for padding the edges of the signal y. By default (pad_mode=\"reflect\"), y is padded on both sides with its own reflection, mirrored around its first and last sample respectively. If center=False, this argument is ignored. .. see also:: np.pad\n",
    "\n",
    "\n",
    "pYIN returns:\n",
    "\n",
    "* f0: time series of fundamental frequencies in Hertz.\n",
    "\n",
    "* voiced_flag: time series containing boolean flags indicating whether a frame is voiced or not.\n",
    "\n",
    "* voiced_prob: time series containing the probability that a frame is voiced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pYIN\n",
    "\n",
    "Let's start by anayzing the pitch of a sweep with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sine sweep\n",
    "dur = 10\n",
    "fmin = 500\n",
    "fmax = 4*500\n",
    "print(\"Sweep goes from\", fmin, \"to\", fmax, \"Hz.\")\n",
    "sr = 44100\n",
    "x_sw = librosa.chirp(fmin, fmax, sr=sr, duration=dur)\n",
    "\n",
    "# plot and play\n",
    "plt.rcParams['figure.figsize'] = [15, 5]\n",
    "reshift._my_plot(x_sw, sr, \"sine sweep\")\n",
    "IPython.display.Audio(x_sw, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pYIN analysis\n",
    "fmin = 60\n",
    "fmax = 2000\n",
    "f_0_sw, voiced_flag, voiced_probs = librosa.pyin(x_sw, fmin=fmin, fmax=fmax, sr=sr)\n",
    "\n",
    "fig, ax = plt.subplots(3)\n",
    "ax[0].plot(f_0_sw)\n",
    "ax[0].set_ylabel(\"f_0\")\n",
    "ax[1].plot(voiced_flag)\n",
    "ax[1].set_ylabel(\"voiced flag\")\n",
    "ax[2].plot(voiced_probs)\n",
    "ax[2].set_ylabel(\"voiced prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works, so now analyze a singing voice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 5\n",
    "dur = 10\n",
    "x_sing, sr = librosa.load(\"../../samples/ave-maria.wav\", offset=pos, duration=dur)\n",
    "\n",
    "# plot and play\n",
    "plt.rcParams['figure.figsize'] = [15, 5]\n",
    "reshift._my_plot(x_sing, sr, \"original signal\")\n",
    "IPython.display.Audio(x_sing, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pYIN analysis\n",
    "fmin = 60\n",
    "fmax = 2000\n",
    "pyin_frame_length = 2048\n",
    "pyin_hop_length = pyin_frame_length // 4\n",
    "f_0_sing, voiced_flag, voiced_probs = librosa.pyin(x_sing, fmin=fmin, fmax=fmax, sr=sr,\n",
    "                                                   frame_length=pyin_frame_length, hop_length=pyin_hop_length)\n",
    "\n",
    "fig, ax = plt.subplots(3)\n",
    "ax[0].plot(f_0_sing)\n",
    "ax[0].set_ylabel(\"f_0\")\n",
    "ax[1].plot(voiced_flag)\n",
    "ax[1].set_ylabel(\"voiced flag\")\n",
    "ax[2].plot(voiced_probs)\n",
    "ax[2].set_ylabel(\"voiced prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work alright too, so lets stick to the default parameters by now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nonlinear frequency scales\n",
    "\n",
    "For mapping the analyzed frequency to a target frequency, we need a scale to get the needed pitch shifting ratio.\n",
    "By now, we have a chromatic and a wholetone scale, which should be sufficient for checking parameters and algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshifter = reshift.Reshifter(sr=sr)\n",
    "\n",
    "f_in = np.linspace(500, 2000, 500)\n",
    "plt.plot(f_in)\n",
    "\n",
    "f_out = reshifter.freq_scale(f_in, scale='chromatic', tune=440)\n",
    "plt.plot(f_out)\n",
    "\n",
    "f_out = reshifter.freq_scale(f_in, scale='wholetone', tune=440)\n",
    "plt.plot(f_out, '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discretized frequency of the analyzed signals are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2)\n",
    "\n",
    "f_0_disc_sw = reshifter.freq_scale(f_0_sw, scale='chrom') # default tuning is 440Hz\n",
    "axs[0].plot(f_0_disc_sw)\n",
    "\n",
    "f_0_disc_sing = reshifter.freq_scale(f_0_sing, scale='chrom')\n",
    "axs[1].plot(f_0_disc_sing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pitches are discretized to semitones.\n",
    "Since the tremolo of the singer goes over a semitone, the target frequency is still jumping between different frequencies.\n",
    "So let's try to get a flat target frequency at parts with tremolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_0_disc_sing = reshifter.freq_scale(f_0_sing, scale='whole')\n",
    "plt.plot(f_0_disc_sing)\n",
    "plt.plot(f_0_sing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still jumping, so use a scale out of thirds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_0_disc_sing = reshifter.freq_scale(f_0_sing, scale='thirds')\n",
    "plt.plot(f_0_disc_sing)\n",
    "plt.plot(f_0_sing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this frequency mapping looks pretty flat.\n",
    "The next step in the frequency discretization algorithm is to calculate the pitch-shifting factor $\\rho[n]$ from the analyzed pitch $f_0[n]$ and the target pitch $f_{out}[n]$\n",
    "\n",
    "$$\\rho[n] = \\frac{f_{out}[n]}{f_0[n]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rho(f_0, f_out):\n",
    "    rho = f_out / f_0\n",
    "    return rho\n",
    "\n",
    "rho_sing = get_rho(f_0_sing, f_0_disc_sing)\n",
    "plt.plot(rho_sing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the pitch-shifting factor which is needed to cancel out the deviation of the input signal from the target pitch.\n",
    "A $\\rho$ of less than one shifts down and a $\\rho$ bigger than one shifts up and one is the original pitch.\n",
    "It can be interpreted as the error signal to the target pitch.\n",
    "\n",
    "The next figure shows how the pitch is compensated to stay at discrete pitches according to the used scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original, = plt.plot(f_0_sing, label=\"original\")\n",
    "shift, = plt.plot(f_0_disc_sing * rho_sing, label=\"shift\")\n",
    "target, = plt.plot(f_0_disc_sing, label=\"target\")\n",
    "plt.legend(handles=[original, shift, target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronization\n",
    "\n",
    "The output pYIN frequency estimations have to be synchronized to the pitch-shifting algorithm.\n",
    "Next we analyze the output data of librosa's pYIN implementation for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the output data sizes of pyin\n",
    "rho_N = pyin_hop_length\n",
    "actual_pyin_hop_size = (x_sing.size - pyin_frame_length) / rho_sing.size\n",
    "\n",
    "print(\"pYIN given frame length:\", pyin_frame_length, \"given rho_N = pYIN_hop_length:\", rho_N)\n",
    "print(\"actual average pYIN hop size:\", actual_pyin_hop_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x[n]; n = 0, ..., N$\n",
    "\n",
    "$N$...length of input signal\n",
    "\n",
    "$f_0[m]; m = 0, ..., M$\n",
    "\n",
    "$M$...length of frequency estimations as output from pYIN\n",
    "\n",
    "$M_z$...length of $f_0$ with zero padding\n",
    "\n",
    "$hop$...hop size of pYIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_len = 1024*8\n",
    "x_test = x_sing[:x_len]\n",
    "f0_test, flag, probs = librosa.pyin(x_test, sr=sr, frame_length=pyin_frame_length, hop_length=pyin_hop_length,\n",
    "                       fmin=200, fmax=1000)\n",
    "print(\"N:\", x_test.size, \"length of x[n] as sample rate\", sr)\n",
    "print(\"pYIN frame length:\", pyin_frame_length, \" and pYIN hop size:\", pyin_hop_length)\n",
    "print( \"M:\", f0_test.size, \"number of f0 estimations\")\n",
    "\n",
    "expected_Mz = x_test.size / pyin_hop_length\n",
    "print(\"Expected Mz:\", expected_Mz, \"calculated number of f0 estimations with zero padding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__So the number of frequency estimations of the librosa pYIN implementation is__\n",
    "\n",
    "$$M = floor(\\frac{N}{hop}) + 1$$\n",
    "\n",
    "for signals of arbitrary length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_len = 1234567\n",
    "x_test = x_sing[:x_len]\n",
    "f0_test, flag, probs = librosa.pyin(x_test, sr=sr, frame_length=pyin_frame_length, hop_length=pyin_hop_length,\n",
    "                       fmin=200, fmax=1000)\n",
    "print(\"N:\", x_test.size, \"length of x[n] as sample rate\", sr)\n",
    "print(\"pyin frame length:\", pyin_frame_length, \" and pyin hop size:\", pyin_hop_length)\n",
    "print( \"M:\", f0_test.size, \"number of f0 estimations\")\n",
    "\n",
    "expected_M = x_test.size // pyin_hop_length + 1\n",
    "print(\"Expected M:\", expected_M, \"calculated number of f0 estimations with zero padding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Solution:__\n",
    "Let's do zero padding of the input signal $x[n]$ to prevent problems later on.\n",
    "This is simple and it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_sing = np.concatenate((x_sing, np.zeros(pyin_frame_length - (x_sing.size % pyin_frame_length))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the upsampling of the control signal, see [here](Synchronize_Control_Rate_and_Audio_Rate.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
